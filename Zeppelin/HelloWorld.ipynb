{
  "metadata": {
    "name": "HelloWorld",
    "kernelspec": {
 "display_name":"zeppelin",     "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Hello World\n## Welcome to the Azure HDInsight Jupyter Notebook\nThis is the equivalent of the Jupyter notebook \u0027HelloWorld\u0027, but runniong in an Apache Zeppelin notebook. Note that Zeppelin allows multiple kernels. Here we are running livy2 and directing it to run both Python code and SQL. commands."
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%livy2.pyspark\nfrom pyspark.sql import *\nfrom pyspark.sql.types import *"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%livy2.pyspark\nfrom pyspark.sql.types import *\nimport csv\nimport io\nfrom io import StringIO\ndef csv_values_in_line(line):\n    sio \u003d StringIO(line)\n    value \u003d next(csv.reader(sio))\n    sio.close()\n    return value\n"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%livy2.pyspark\n# Create a Spark dataframe and table from sample data (note this is NOT a Pandas dataframe)\ncsvFile \u003d spark.read.csv(\u0027/HdiSamples/HdiSamples/SensorSampleData/hvac/HVAC.csv\u0027, header\u003dTrue, inferSchema\u003dTrue)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%livy2.pyspark\n# How many rows in dataframe?\ncsvFile.count()"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%livy2.sql\nDROP TABLE IF EXISTS hvac_ss01shh;"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%livy2.pyspark\ncsvFile.createOrReplaceTempView(\"hvac_ss01shh\")"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%livy2.sql\nSHOW TABLES;"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%livy2.pyspark\nspark.sql(\"SELECT count(*) from hvac_ss01shh\").show()"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%livy2.sql\nSELECT * FROM hvac_ss01shh"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%livy2.sql\nDESCRIBE TABLE hvac_ss01shh"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%livy2.sql\nSELECT `buildingID`, (targettemp - actualtemp) AS `temp_diff`, date FROM hvac_ss01shh WHERE date \u003d \"6/1/13\""
    }
  ]
}